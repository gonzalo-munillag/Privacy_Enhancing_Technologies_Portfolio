{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to TenSEAL\n",
    "\n",
    "TenSEAL is a tensor library, just like PyTorch or Tensorflow, however, instead of manipulating tensors that holds plain data, tensors in TenSEAL holds encrypted data using mainly the CKKS scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Context\n",
    "\n",
    "The first object you want to create whenever you deal with TenSEAL is the context. It provides ways to control how the computation is performed, generate and holds the keys (e.g. the secret-key and public-key) required during encryption and computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=8192, coeff_mod_bit_sizes=[60, 40, 40, 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line created a context for CKKS encryption, using those specific parameters. We will provide some intuition on how to choose those parameters shortly. The context creation above took care of generating keys required, and you can now get the secret-key for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tenseal.enc_context.SecretKey at 0x7f391eb8d280>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk = context.secret_key()\n",
    "sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuitions for Parameter Selection in CKKS\n",
    "\n",
    "It's hard to choose the right parameters for a certain computation, but if you have some intuitions of what every parameter might be affecting, you can make some experiments using some different variants and see which works best for your use case. Below are some intuitions for choosing the parameters:\n",
    "\n",
    "- For a given security level (e.g. 128-bits security) and a polynomial modulus degree (e.g. 8192) there is an upper bound for the `sum(coeff_mod_bit_sizes)`. If the upper bound is surpassed, there is a need to use a higher polynomial modulus degree (e.g. 16384) in order to make sure we still have the required security level.\n",
    "- The multiplicative depth is controlled by `len(coeff_mod_bit_sizes) - 2`. The above context provide a multiplicative depth of 2 for example. A `coeff_mod_bit_sizes=[60, 40, 40, 40, 60]` would have provided 3.\n",
    "- All elements of `coeff_mod_bit_sizes[1: -1]` should be equal in TenSEAL, since it takes care of rescaling ciphertexts. And we also want to use this same number of bits (e.g. 2 ^ 40) for the scale during encryption.\n",
    "- The scale of ciphertext (which should be equal to `coeff_mod_bit_sizes[1: -1]`) controls the precision of the fractional part. The bigger, the more precise.\n",
    "- The difference between `coeff_mod_bit_sizes[-1]` and `coeff_mod_bit_sizes[-2]` (or the scale) controls the precision in the integer part when all multiplication have been consumed. The bigger, the more precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors\n",
    "\n",
    "Now we start creating some encrypted tensors. You can pass in any tensor-like object (it has been tested with torch and numpy), and TenSEAL would take care of encrypting it using the keys and parameters stored in the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tenseal.tensors.ckkstensor.CKKSTensor at 0x7f391eb8d700>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "plain_tensor = np.random.randn(2, 3)\n",
    "encrypted_tensor = ts.ckks_tensor(context, plain_tensor, scale=2**40)\n",
    "encrypted_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set the `global_scale` in the context so that you never need to pass the scale again and again during tensor creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tenseal.tensors.ckkstensor.CKKSTensor at 0x7f391eb8d130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.global_scale = 2 ** 40\n",
    "encrypted_tensor = ts.ckks_tensor(context, plain_tensor)\n",
    "encrypted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tenseal.tensors.plaintensor.PlainTensor object at 0x7f391eb8d7c0>\n"
     ]
    }
   ],
   "source": [
    "print(encrypted_tensor.decrypt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PlainTensor object is a tensor that we mainly use internally to represent tensors with plain values. You can always call `tolist()` to convert it to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6935322486262878, -0.1971640039349987, -0.6806255185457504], [-0.6699472410544948, 1.3804208496159256, -0.05087860773279334]]\n"
     ]
    }
   ],
   "source": [
    "print(encrypted_tensor.decrypt().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69353225 -0.197164   -0.68062552]\n",
      " [-0.66994724  1.38042085 -0.05087861]]\n"
     ]
    }
   ],
   "source": [
    "# you can compare it to the plain tensor\n",
    "print(plain_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute on Encrypted Tensors\n",
    "\n",
    "CKKSTensor support addition, subtraction, and multiplication with scalar and tensor-like values. Let's see an example computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_result = (encrypted_tensor + 2) * -3 - plain_tensor\n",
    "expected_result = (plain_tensor + 2) * -3 - plain_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-3.2258715329047387, -5.211344710933246, -3.277498460263318],\n",
       " [-3.320211576555451, -11.521684756232458, -5.796486356321944]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrypted_result.decrypt().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.22587101  -5.21134399  -3.27749793]\n",
      " [ -3.32021105 -11.52168339  -5.79648557]]\n"
     ]
    }
   ],
   "source": [
    "print(expected_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make dot operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 0.2651245105129444\n",
      "expected: 0.2651244888032714\n"
     ]
    }
   ],
   "source": [
    "# inner product\n",
    "vec1 = np.random.randn(5)\n",
    "vec2 = np.random.randn(5)\n",
    "enc_vec1 = ts.ckks_tensor(context, vec1)\n",
    "enc_vec2 = ts.ckks_tensor(context, vec2)\n",
    "print(\"result:\", enc_vec1.dot(enc_vec2).decrypt().tolist())\n",
    "print(\"expected:\", vec1.dot(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [[1.073233344180927, -1.244239415938116, -3.551577053659822, 0.1420384564803854], [0.07071465417811199, 2.8233036003449787, 3.6074107515157654, 0.38663331431247283]]\n",
      "expected: [[ 1.0732332  -1.24423924 -3.55157659  0.14203844]\n",
      " [ 0.07071466  2.82330321  3.60741026  0.38663327]]\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "mat1 = np.random.randn(2, 3)\n",
    "mat2 = np.random.randn(3, 4)\n",
    "enc_mat1 = ts.ckks_tensor(context, mat1)\n",
    "enc_mat2 = ts.ckks_tensor(context, mat2)\n",
    "print(\"result:\", enc_mat1.dot(enc_mat2).decrypt().tolist())\n",
    "print(\"expected:\", mat1.dot(mat2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched computation\n",
    "\n",
    "We previously discussed in the CKKS concept that a single ciphertext can hold multiple values (a vector of values), without affecting the computation or memory costs. However, we didn't use that feature so far. So now, we are going to use this capability to compute on a batch of matrices at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [[1.8717073107411415, -1.646466405990874, 0.9077041758823494, 1.0415948014188408], [-1.5680046326356467, 1.127137122149572, -1.6876492182683538, -0.5806471841318446]]\n",
      "expected: [[ 1.87170707 -1.64646619  0.90770405  1.04159466]\n",
      " [-1.56800442  1.12713697 -1.68764899 -0.58064711]]\n"
     ]
    }
   ],
   "source": [
    "# a single ciphertext can hold up to `poly_modulus_degree / 2` values\n",
    "# so let's use all the slots available\n",
    "batch_size = 8192 // 2 #  4096\n",
    "mat1 = np.random.randn(batch_size, 2, 3)\n",
    "mat2 = np.random.randn(3, 4)\n",
    "# batch is by default set to False, we have to turn it on to use the packing feature of ciphertexts\n",
    "enc_mat1 = ts.ckks_tensor(context, mat1, batch=True)\n",
    "enc_mat2 = ts.ckks_tensor(context, mat2)\n",
    "# let's just compare the first result matrix in the batch\n",
    "print(\"result:\", enc_mat1.dot(enc_mat2).decrypt().tolist()[0])\n",
    "print(\"expected:\", mat1.dot(mat2)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Details\n",
    "\n",
    "This section provides more details about the library and how some things happens under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Computation\n",
    "\n",
    "TenSEAL takes advantage of parallel computation whenever possible. It uses by default the maximum number of threads the system can run in parallel, but someone can specify that during context creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_parallel_context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,\n",
    "    coeff_mod_bit_sizes=[60, 40, 40, 60],\n",
    "    n_threads=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decryption\n",
    "\n",
    "you might have been wondering how is decryption not requiring a secret-key? But it's just because the context by default holds all the keys, and is considered a private asset. If you want to make it public, then you just call `make_context_public()`. Make sure you save the secret-key somewhere before that to use it later for decryption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = context.secret_key()\n",
    "context.make_context_public()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the current context of the tensor doesn't hold a secret_key, please provide one as argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e5e172f8f9a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# now let's try decryption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menc_mat1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecrypt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenseal-0.3.0a2-py3.8-linux-x86_64.egg/tenseal/tensors/ckkstensor.py\u001b[0m in \u001b[0;36mdecrypt\u001b[0;34m(self, secret_key)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecrypt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecret_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ts.enc_context.SecretKey\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"ts.PlainTensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decrypt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecret_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecret_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlainTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenseal-0.3.0a2-py3.8-linux-x86_64.egg/tenseal/tensors/abstract_tensor.py\u001b[0m in \u001b[0;36m_decrypt\u001b[0;34m(self, secret_key)\u001b[0m\n\u001b[1;32m     83\u001b[0m     ) -> Union[ts._ts_cpp.PlainTensorDouble, ts._ts_cpp.PlainTensorInt64, List[float], List[int]]:\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msecret_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecrypt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecret_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSecretKey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecrypt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecret_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: the current context of the tensor doesn't hold a secret_key, please provide one as argument"
     ]
    }
   ],
   "source": [
    "# now let's try decryption\n",
    "enc_mat1.decrypt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tenseal.tensors.plaintensor.PlainTensor at 0x7f391eb8dc70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to explicitly pass the secret-key\n",
    "enc_mat1.decrypt(sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should always make a context public before sending it to other parties to compute on encrypted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization\n",
    "\n",
    "Speaking of sending the context and encrypted data, can we serialize these objects? And the answer is yes! There is a `serialize` method for every serializable object, like the context and tensors. Although, tensors have a slightly different ways of being loaded, let's see through an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_context = context.serialize()\n",
    "type(ser_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_tensor = encrypted_tensor.serialize()\n",
    "type(ser_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tenseal.enc_context.Context at 0x7f391eb8dfa0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_context = ts.context_from(ser_context)\n",
    "loaded_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As tensors always require to be linked to a context, we need to know which context to link the tensor to during deserialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tenseal.tensors.ckkstensor.CKKSTensor at 0x7f391eb8dd30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_enc_tensor = ts.ckks_tensor_from(loaded_context, ser_tensor)\n",
    "loaded_enc_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is also a way to do it the lazy way, deserializing, then linking it to a specific context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "missing context",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2e85dadfcc1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlazy_loaded_enc_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_ckks_tensor_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# try to operate on a tensor that in not linked to a context yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlazy_loaded_enc_tensor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenseal-0.3.0a2-py3.8-linux-x86_64.egg/tenseal/tensors/abstract_tensor.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"AbstractTensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"AbstractTensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenseal-0.3.0a2-py3.8-linux-x86_64.egg/tenseal/tensors/ckkstensor.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"CKKSTensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_operand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: missing context"
     ]
    }
   ],
   "source": [
    "lazy_loaded_enc_tensor = ts.lazy_ckks_tensor_from(ser_tensor)\n",
    "# try to operate on a tensor that in not linked to a context yet\n",
    "lazy_loaded_enc_tensor + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tenseal.tensors.ckkstensor.CKKSTensor at 0x7f391eb8d1f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You have to first link it\n",
    "lazy_loaded_enc_tensor.link_context(loaded_context)\n",
    "lazy_loaded_enc_tensor + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plug all these features with a system that can pass data between parties and we can do encrypted machine learning inference, where one party encrypts its data and send it to another party that do the inference while data stays encrypted, then send back the encrypted result. The initial party can then use the secret-key to decrypt the result. And fortunately, we already have Duet in PySyft to do this!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
