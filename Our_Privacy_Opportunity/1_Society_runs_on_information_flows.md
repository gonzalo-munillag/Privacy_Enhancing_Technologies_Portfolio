# Our Privacy Opportunity

## Main takeaways

Create information flows within society, which in turn creates social good. Privacy is in service of this higher purpose, it is a subtopic. Privacy technology is not only about privacy, but it can also be used to prevent misinformation or inappropriate information flows. 

The promise of privacy-enhancing technologies: How can society accomplish its goals with lower risk, higher accuracy, faster speed, more aligned incentives than better than before through better information flows? This must be answered by entrepreneurs and companies.

There is a balance between privacy and transparency that must be accounted for in the design of any appropriate information flow.

## Goals of the course, including short summaries 

1. Learn how information flows affect society today.
Information flows are everywhere, in any transaction. Depending on how they are designed, it can create or damage social good. 
2. Learn what components make up an information flow.
The sender, the message, and the receiver. The nuances of each of these components make an information flow appropriate or not. Privacy-enhancing technologies ensure that these components are the appropriate ones for the given context of communication.
3. Learn how to determine success and fail criteria for an information flow. 
A successful information flow depends on whether the individual communicating agrees that its design fits the context in which the information flow is deployed. 

 ## #0 Introduction

Privacy infringement, fake news, disinformation, corruption, addiction, polarization, depression, and democracy are under threat due to digital media, which revolves around **information**, its ownership, and how it flows or does not flow.
The problem may be distilled into this question: ***"Who should be told what?"***. 
Technology innovations change its answer, these innovations change how information flows in society, who owns it, and who can create value from it.

This will have an impact on you, the products you buy, news, the relationships with people and the government, geopolitics, research, and the success of organizations. 
It is important to understand the future transitions in information flow.

## #1 Society runs on information flows

***"In this lesson, we walk through some of the most important challenges in society, and we identify how the privacy-transparency tradeoff underpins them."***

### Information flows (IFlow)
 
Information flows are everywhere, each day we share our location, sleeping patterns, heartbeats, medical records, etc. to receive a service, exchange goods, or to collaborate with others. Information flows are at the core of the human experience.  
Basic components: sender, message, and receiver. But it is more nuanced, as there could be multiple and unknown receivers or senders, even deceitful, or even eavesdroppers. Inability to facilitate a specific kind of information flow underpins a multitude of societies' deepest and pervasive problems across history and modern-day society.

**Quiz questions**

*What is the best definition of an information flow?*  
A flow of bits from a sender to a receiver with some probability. The semantics of "Probability" is applied to the three basic components.

### The privacy dilemma

**A lack of an ideal privacy flow is what creates the dilemma.**  
**Trade-off between whether or not to reveal information, where revealing information can provide benefits to society while it could also incur harm to individuals.**

Sometimes, IFlows fail to exactly to transmit information only to specific entities.
Leaky IFlows: Reveal more information than intended.
Insufficient IFlows: Fail to fully convey the information or persuade recipients of its veracity or provenance.

Privacy violation in society, of an individual, depends more on the flow than on the information itself. It is important to know who will receive this information, and the context: Helen Nissenbaum - "Contextual Integrity", i.e. while sharing information in one context is appropriate, in another might not be.
E.g. someone seeing you in the street vs. someone taking a picture of you in the street. First of all, this brings a new Iflow that you did not expect; and second of all, as your face is unique, it may be used to identify you in other situations where the identification was not triggered by you.
It is not about secrecy, but about some data flow unexpectedly, as people would otherwise act differently. Characterize appropriateness. 
Privacy is about the flow, not the information, the question is about appropriate IFlows, not privacy.

**Quiz questions**

*What is the most accurate definition of privacy?*  
The ability to ensure flows of information that satisfy social norms.
Agency: the ability to control how information is used - especially sensitive information.  

*What is contextual integrity?*  
A description of when people in society feel their privacy is violated
"As Helen talks about in her video - contextual integrity's core aim is to pinpoint when people feel that their privacy is violated. This is different from other definitions of privacy which attempt to create a single ontology or simple rule for when privacy is violated or not violated. But Helen points out that people in a society already know viscerally when their privacy has been violated - and contextual integrity is an attempt at describing that reaction."  

*When are you working with private data?*  
When someone cares about how you might use the information because privacy is about the flow of information in the context of social norms.

### Data is fire

*When people might care about an Iflow?*
Even apparently harmless data, e.g. grocery purchases or the way you walk, can identify you in a crowd, and profile you, making assumptions about your life. Moreover, changes in your life are reflected in the comparison between past and present data, therefore, even though you might not care about today's bread purchase, stopping buying bread in the future may leak to the health insurers that you have recently been diagnosed with diabetes. Anonymizing data is not enough, it has been shown that combining innocuous attributes could uniquely identify you. But for some malicious use cases, you do not even need the name of an individual, as long as you profile him/her and know how to reach him/her, then you can target information that changes his/her behavior towards a third party's goal. Privacy also transcends individuals, but also at a community or national level.  
Anonymization is such a weak measure that there exist business models of companies dedicated to monetizing how clever they are at bypassing them, extracting sensitive data from seemingly non-sensitive data, "You are always playing with fire".

**Privacy is an unmet market opportunity** for industry players (Identifying non existing appropriate IFlows for different target groups, like the end-to-end encryption of Whatsapp or the delete-after-viewing feature of Snap Chat), and there are also unseen social costs from missed opportunities by research institutions (Failure to accomplish important outcomes of IFlows).

**Quiz questions**

*Why is data "like fire"?*  
Because of its dual-use, it can be copied and shared an infinite number of times, it can help us prosper, it can cause irreparable harm.

*Is a record of whether someone buys bread private data?*
Yes, it could be.

*If I had a list of whether people like movies - and I replace their names with random names - is it still private/sensitive data?*  
Yes, it's still private because data anonymization doesn't work. 

*If I can't link anonymized data to someone's exact identity - is it still private information?*  
Yes, it could be. Because just because you can't identify an individual - if you could identify a community you can still use that data to cause harm.

## The transparency dilemma

**One is forced to decide without the information necessary to make it**

Locking down data completely would not make a better world (maximizing privacy), leads to a lack of transparency and therefore malicious endeavors may be hidden or the upside potential of e.g. research is curtailed.  
Accountability is based on designing IFlows to hold someone accountable, bad actors are detected stopped, and avoided.  
They also have unmet market opportunities, e.g. if you can construct IFlows to help entities make decisions while preventing bad actors from attaining their goals. 

**Quiz questions**

*What is the best definition of a transparency dilemma?*  
When someone doesn't have access to enough information to accurately make a decision. When life doesn't have enough transparency - it creates dilemmas where people don't know what decisions to make.

## The privacy-transparency Pareto frontier

Privacy and transparency are a Pareto trade-off, but with innovations, one may get more of both. Companies and researchers may have both accuracies of data and privacy of their customers.

## Healthy Market Competition for Information Services

By default, digital services that handle personal data lock you in. They are inherently anti-competitive, as it is in their interest to avoid other services to offer you better (more tailored) services, and thus, they prevent from letting this data to leak elsewhere, therefore, regulation entrenches this lock-in further. This is good, but at the same time, it provides a monopoly to the service provider who locked you in. This makes data centralize and if the service provider harasses its users, then these are forced to either continue using the rogue service or switching to another service provider, but the service would degrade as the new service provider needs to start from scratch with the new user. But, if we let companies share the data without barriers, then data can be exploited by malicious entities.  

Scenario 1: The user moves away with his/her data at will to another service.
Scenario 2: The user consents the data holder to share data with another data holder (service provider).
The difference between scenarios is that one is pushed by the users' interest and the other by a company's interest in profit, instantiating a perhaps unknowing user.

Lock-in = monopoly: Artificially increases scarcity, and therefore prices, and reduces the need to provide the service appropriately.  
**Interoperability** avoids the lock-in effect. **Competitive compatibility** is a strategy to make a new business' application, to be compatible with a competitor's app. This is used to defeat centralization, it lowers the switching cost, switching in steps.

Privacy is about **user agency**, it provides the user with the means to choose the right IFlow.

**Quiz questions**

*Restricting how private data can be shared increases privacy and reduces harm*  
False, it's extremely important that if we want to protect privacy - we need the organization to be forced to share information in many cases - especially when a user wants to switch services. This allows privacy concerns to drive market competition.

*Under GDPR - if you ask for your data a company has to give it to you (w/ limited exceptions)*  
Yes

*Privacy is ONLY about preventing information from being shared in inappropriate contexts.*  
False, sometimes satisfying privacy is about forcing companies to share or delete your data in a specific way or at a specific time.

### Feedback Mechanisms & Information Flows & other topics

Feedback is everywhere and necessary to create better products, but due to privacy reasons, sometimes you cannot get feedback from customers, inter alia.

An interesting example of how people in a city themselves keep it safe ("eyes on the street"), by reporting to the police when something is off in a street. That is a feedback mechanism in itself, by the people and for the people. This does not feel like surveillance, it is not sent to a centralized database unless it is necessary. The question is how to apply this type of thinking to the digital world. This is bottom-up. This is more effective and less intrusive.

Great application that optimizes for consensus: [Polis](https://en.wikipedia.org/wiki/Polis_(app)). It allows a population to have collective debates about social topics.

Incentives are crucial to build a successful application, and incentives leak from the metrics they measure. E.g., Netflix incentivizes people to spend more time in their application, which increases the metric of attention, which makes Netflix successful. But how would e.g. Netflix optimize for shows that help in the sleep of users? Netflix would then need biometric readings from your smartwatch. Netflix could also help you to improve connections with others, boost your self-esteem, quit addictions, find good role models, etc. Attention is a poor metric, it does not help you to measure true value, and it is a metric widely used across services. 

An interesting example of war conflicts, how both nations in dispute might overestimate their chances of winning if a war breaks. A concrete example was given with India and Pakistan, the US mediated between the two and rectified their estimations.  
What is interesting, is that in total blindness, one may overestimate the chances of winning (total privacy), and with total transparency in theory you could have peace, but, it is too risky as in reality one entity might secretively hide information, it is impossible to enforce. So the middle ground with the third party is a trade-off between the two paradigms.

*Is what you are told actually true?*  
Centralizing of resources to facilitate a global news network, has a tremendous amount of influence in the world's events? Many people's decisions are based on what we hear, news is one of the most important IFlows in the world. What IFlows should exist and which collateral damage may it cause? E.g., journalists' sources made public would bring more value but could put the individuals into life's harm.  
New media, has redefined the IFLows facilitated by the freedom of speech. And what happens if the information is false? Fake news = virus, consider the reproduction number R_0 (Expected number of cases directly generated by one case), if R_0 is larger than one, then the disease is spread all over, same applies to the news. In a pre-digital age, R_0 of a person telling fake news might be 1%, as most people are rational, but today it may be way above 100%, as one can reach millions of people over the internet and some of them might not be skeptical. People are not trained journalists. Detecting fake news by AI is quite difficult, as only based on the text you cannot know, the key is in the events that originate it.

**Quiz questions**

*What is a feedback mechanism?*  
A flow of information allowing someone to learn how others feel about their actions

*Does data anonymization protect people from harm?*  
No, anonymized data can still hurt people.

*If someone isn't listed in a dataset - can that person still be harmed if the data is shared?*  
Yes, data can cause people to learn facts that can harm people who aren't listed in that dataset.

####  Quotes

***"The internet is today's printing press"*** - Andrew Trask

#### Interesting links and other things

[First issues with drone laws in the U.S.A](https://www.theverge.com/2021/1/1/22209558/google-wing-faa-drone-remote-id-broadcast-rule-privacy-security)
Alphabet would like to track drone location via modems, but it has a set of drawbacks, so the proposals lean towards radio frequencies as if the drones had a license plate only visible locally.

[Data is fire](https://ystrickler.medium.com/data-is-fire-92a110557ef8)
Data brings growth and innovation, but it is also dangerous. We are what we measure, our economy revolves around making money. Other measurable metrics however have brought new things that are valuable and exchangeable, like time, loyalty, social desirability (China's system to allocate human rights to its citizens), fairness. Furthermore, there is a rising "Fuck the algorithm" movement.

Cory Doctorow, a writer I am looking forward to reading.

Smart energy meters are very pervasive, they could be a tool for mass surveillance, including electric vehicles.
